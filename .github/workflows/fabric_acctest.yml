name: Fabric Acceptance Tests
# This workflow determines whether a PR comes from an external fork
# (which requires approval from us) or from a branch on this repository
# (which means it was made by us and can run immediately).  Once a PR
# is approved, the PR code gains access to secrets referenced in this
# workflow.

# The 'build' job and subsequent jobs, are executed only when the pull
# request is not a draft, regardless of whether it is from an internal
# branch or external fork.

# Any changes to this job, even from internal contributors, require heavy scrutiny.

on:
  pull_request_target:
    types: [opened, synchronize, reopened, ready_for_review]
    paths:
      - 'go.mod'
      - 'go.sum'
      - '**fabric**'
      - '!LICENSE'
      - '!**.md'
      - '!website/**'
      - '!docs/**'
      - '!.github/ISSUE_TEMPLATE/**'
  workflow_dispatch:

permissions:
  pull-requests: read
  contents: read

jobs:

  authorize:
    if: (github.event_name == 'workflow_dispatch') || (github.event_name == 'pull_request_target' && github.event.pull_request.draft == false)
    environment:
      ${{ github.event_name == 'pull_request_target' &&
      github.event.pull_request.head.repo.full_name != github.repository &&
      'external' || 'internal' }}
    runs-on: ubuntu-latest
    concurrency:
      group: ${{ github.event_name == 'pull_request_target' && format('fabric-acctest-authorize-pr-{0}', github.event.pull_request.number) || 'fabric-acctest-authorize' }}
      cancel-in-progress: true
    steps:
      - run: true

  build:
    name: Build
    needs: authorize
    runs-on: ubuntu-latest
    timeout-minutes: 10
    steps:

      - name: Check out code into the Go module directory
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4
        with:
          ref: ${{ github.event.pull_request.head.sha || github.ref }}

      - name: Set up Go
        uses: actions/setup-go@d35c59abb061a4a6fb18e82ac0862c26744d6ab5 # v5
        with:
          go-version-file: './go.mod'
        id: go

      - name: Get dependencies
        run: |
          go mod download

      - name: Build
        run: |
          go build -v .

  test-PNFV:
    name: Matrix Test
    needs: build
    runs-on: ubuntu-latest
    env:
      EQUINIX_API_ENDPOINT: "https://uatapi.equinix.com"
    timeout-minutes: 240
    strategy:
      fail-fast: false
      matrix:
        version:
          - stable
        terraform:
          - '1.5'
    steps:

      - name: Check out code into the Go module directory
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4
        with:
          ref: ${{ github.event.pull_request.head.sha || github.ref }}

      - name: Set up Go
        uses: actions/setup-go@d35c59abb061a4a6fb18e82ac0862c26744d6ab5 # v5
        with:
          go-version-file: './go.mod'
        id: go

      - name: Get dependencies
        run: |
          go mod download

      - uses: hashicorp/setup-terraform@b9cd54a3c349d3f38e8881555d616ced269862dd # v3
        with:
          terraform_version: ${{ matrix.terraform }}
          terraform_wrapper: false

      - name: TF Fabric PNFV acceptance tests
        timeout-minutes: 180
        env:
          TF_ACC: "1"
          TF_ACC_FABRIC_CONNECTIONS_TEST_DATA: ${{ secrets.TF_ACC_FABRIC_CONNECTIONS_TEST_DATA }}
          TF_ACC_FABRIC_DEDICATED_PORTS: ${{ secrets.TF_ACC_FABRIC_DEDICATED_PORTS }}
          EQUINIX_API_CLIENTID: ${{ secrets.EQUINIX_API_CLIENTID_PNFV }}
          EQUINIX_API_CLIENTSECRET: ${{ secrets.EQUINIX_API_CLIENTSECRET_PNFV }}
          METAL_AUTH_TOKEN: ${{ secrets.METAL_AUTH_TOKEN }}
        run: |
          go test ./... -v -coverprofile coverage_pnfv.txt -covermode=atomic -count 1 -parallel 8 -run "(PNFV)" -timeout 180m | tee pnfv_test_output.log

      - name: Upload PNFV Testing Log
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4
        with:
          name: pnfv_test_logs
          path: pnfv_test_output.log

      - name: Check if Tests are passed
        run: sh scripts/check_tests.sh pnfv_test_output.log

      - name: Sweeper PNFV
        if: ${{ always() }}
        env:
          EQUINIX_API_CLIENTID: ${{ secrets.EQUINIX_API_CLIENTID_PNFV }}
          EQUINIX_API_CLIENTSECRET: ${{ secrets.EQUINIX_API_CLIENTSECRET_PNFV }}
          METAL_AUTH_TOKEN: ${{ secrets.METAL_AUTH_TOKEN }}
          SWEEP: "all" #Flag required to define the regions that the sweeper is to be ran in
          SWEEP_ALLOW_FAILURES: "true" #Enable to allow Sweeper Tests to continue after failures
          SWEEP_DIR: "./equinix"
        run: |
          # Added sweep-run to filter Fabric PNFV test
          go test $(go list ./... | grep 'internal/sweep\|equinix/equinix') -v -timeout 180m -sweep=${SWEEP} -sweep-allow-failures=${SWEEP_ALLOW_FAILURES} -sweep-run=$(grep -or 'AddTestSweepers("[^"]*"' | grep "_fabric_" | cut -d '"' -f2 | paste -s -d, -)

      - name: Upload coverage to Codecov
        if: ${{ always() }}
        uses: codecov/codecov-action@18283e04ce6e62d37312384ff67231eb8fd56d24 # v5
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          files: ./coverage_pnfv.txt

  test-PFCR:
    name: Matrix Test
    needs: build
    runs-on: ubuntu-latest
    env:
      EQUINIX_API_ENDPOINT: "https://uatapi.equinix.com"
    timeout-minutes: 240
    strategy:
      fail-fast: false
      matrix:
        version:
          - stable
        terraform:
          - '1.5'
    steps:

      - name: Check out code into the Go module directory
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4
        with:
          ref: ${{ github.event.pull_request.head.sha || github.ref }}

      - name: Set up Go
        uses: actions/setup-go@d35c59abb061a4a6fb18e82ac0862c26744d6ab5 # v5
        with:
          go-version-file: './go.mod'
        id: go

      - name: Get dependencies
        run: |
          go mod download

      - uses: hashicorp/setup-terraform@b9cd54a3c349d3f38e8881555d616ced269862dd # v3
        with:
          terraform_version: ${{ matrix.terraform }}
          terraform_wrapper: false

      - name: TF Fabric PFCR acceptance tests
        timeout-minutes: 180
        env:
          TF_ACC: "1"
          TF_ACC_FABRIC_CONNECTIONS_TEST_DATA: ${{ secrets.TF_ACC_FABRIC_CONNECTIONS_TEST_DATA }}
          TF_ACC_FABRIC_DEDICATED_PORTS: ${{ secrets.TF_ACC_FABRIC_DEDICATED_PORTS }}
          TF_ACC_FABRIC_MARKET_PLACE_SUBSCRIPTION_ID: ${{ secrets.TF_ACC_FABRIC_MARKET_PLACE_SUBSCRIPTION_ID }}
          TF_ACC_FABRIC_STREAM_TEST_DATA: ${{ secrets.TF_ACC_FABRIC_STREAM_TEST_DATA }}
          EQUINIX_API_CLIENTID: ${{ secrets.EQUINIX_API_CLIENTID_PFCR }}
          EQUINIX_API_CLIENTSECRET: ${{ secrets.EQUINIX_API_CLIENTSECRET_PFCR }}
          METAL_AUTH_TOKEN: ${{ secrets.METAL_AUTH_TOKEN }}
        run: |
          go test ./... -v -coverprofile coverage_pfcr.txt -covermode=atomic -count 1 -parallel 8 -run "(PFCR)" -timeout 180m | tee pfcr_test_output.log

      - name: Upload PFCR Testing Log
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4
        with:
          name: pfcr_test_logs
          path: pfcr_test_output.log

      - name: Check if Tests are passed
        run: sh scripts/check_tests.sh pfcr_test_output.log

      - name: Sweeper PFCR
        if: ${{ always() }}
        env:
          EQUINIX_API_CLIENTID: ${{ secrets.EQUINIX_API_CLIENTID_PFCR }}
          EQUINIX_API_CLIENTSECRET: ${{ secrets.EQUINIX_API_CLIENTSECRET_PFCR }}
          METAL_AUTH_TOKEN: ${{ secrets.METAL_AUTH_TOKEN }}
          SWEEP: "all" #Flag required to define the regions that the sweeper is to be ran in
          SWEEP_ALLOW_FAILURES: "true" #Enable to allow Sweeper Tests to continue after failures
        run: |
          # Added sweep-run to filter Fabric PFCR test
          go test $(go list ./... | grep 'internal/sweep\|equinix/equinix') -v -timeout 180m -sweep=${SWEEP} -sweep-allow-failures=${SWEEP_ALLOW_FAILURES} -sweep-run=$(grep -or 'AddTestSweepers("[^"]*"' | grep "_fabric_" | cut -d '"' -f2 | paste -s -d, -)

      - name: Upload coverage to Codecov
        if: ${{ always() }}
        uses: codecov/codecov-action@18283e04ce6e62d37312384ff67231eb8fd56d24 # v5
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          files: ./coverage_pfcr.txt

  upload-test-report:
    name: Upload Testing Report
    if: always()
    needs: [ test-PNFV, test-PFCR ]
    runs-on: ubuntu-latest
    outputs:
      message: ${{ steps.slack_message.outputs.message }}

    steps:
      - name: Set up Go
        uses: actions/setup-go@d35c59abb061a4a6fb18e82ac0862c26744d6ab5 # v5
        id: go

      - name: Set up Python3
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065 # v5
        with:
          python-version: '3.13'

      - name: Get dependencies
        run: |
          go install github.com/thogarty/go-junit-report/v2@latest
          pip3 install junit2html

      - name: Download PNFV Test Logs
        uses: actions/download-artifact@d3f86a106a0bac45b974a628896c90dbdf5c8093 # v4
        with:
          name: pnfv_test_logs

      - name: Download PFCR Test Logs
        uses: actions/download-artifact@d3f86a106a0bac45b974a628896c90dbdf5c8093 # v4
        with:
          name: pfcr_test_logs

      #      - name: Create HTML Testing Report
      #        run: |
      #          cat pfcr_test_output.log pnfv_test_output.log > uat_test_report.log
      #          go-junit-report -in uat_test_report.log > uat_test_report.xml && python3 -m junit2htmlreport uat_test_report.xml uat_test_report.html

      - name: Create HTML Testing Report
        run: |
          # Combine logs but ensure they're properly formatted for go-junit-report
          cat pfcr_test_output.log pnfv_test_output.log > uat_test_report.log
          # Convert Go test output to JUnit XML
          cat uat_test_report.log | go-junit-report > uat_test_report.xml
          # Generate HTML report from XML
          python3 -m junit2htmlreport uat_test_report.xml uat_test_report.html
          
          echo "=== uat test report log file ==="
          cat uat_test_report.log
          
          echo "=== debug report xml file ==="
          cat uat_test_report.xml
          
          echo "=== debug report html file ==="
          cat uat_test_report.html
          
          # Extract total tests and failures from the first  tag
          total_tests=$(grep -oP 'tests="\K[0-9]+' uat_test_report.xml | head -n 1)
          total_failing_tests=$(grep -oP 'failures="\K[0-9]+' uat_test_report.xml | head -n 1)
      
          # Calculate total passing tests
          total_passing_tests=$((total_tests - total_failing_tests))
      
          echo "Total Number of Tests: $total_tests"
          echo "Total Number of Failing Tests: $total_failing_tests"
          echo "Total Number of Passing Tests: $total_passing_tests"
      
          # Create a summary HTML snippet
          summary_html="<h1>Test Summary</h1>
          <h2>Total Number of Tests: $total_tests</h2>
          <h2>Total Number of Passing Tests: $total_passing_tests</h2>
          <h2>Total Number of Failing Tests: $total_failing_tests</h2>"

          # Append the summary to the beginning of the HTML report
          echo "$summary_html" | cat - uat_test_report.html > temp && mv temp uat_test_report.html

      - name: Prepare slack message
        id: slack_message
        if: always()
        shell: bash
        run: |
          tests=$(grep '<testsuite ' uat_test_report.xml | sed -n 's/.*tests="\([0-9]*\)".*/\1/p' | awk '{s+=$1} END {print s}')
          errors=$(grep '<testsuite ' uat_test_report.xml | sed -n 's/.*failures="\([0-9]*\)".*/\1/p' | awk '{s+=$1} END {print s}')

          message="*Results:* $((tests-errors)) Passed, $errors Errors"
          echo "message<<EOF" >> $GITHUB_OUTPUT
          echo "$message" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT    

      - name: Notify Slack
        uses: slackapi/slack-github-action@b0fa283ad8fea605de13dc3f449259339835fc52 # v2
        if: always()
        with:
          method: chat.postMessage
          token: ${{ secrets.SLACK_ACCESS_TOKEN }}
          payload: |
            channel: digin-panthers-gha-automation

            attachments:
              - color: ${{ job.status == 'success' && 'good' || job.status == 'failure' && 'danger' || 'warning' }}
                text: |
                    *Repository:* <${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}|${{ github.repository }}>
                    *Workflow:* ${{ github.workflow }}           
                    *Status:* ${{ job.status }}
                    *Results:* ${{ steps.slack_message.outputs.message }}
                    *Triggered by:* <@${{ github.actor }}>       

      - name: Upload HTML Testing Report
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4
        with:
          name: UAT Terraform Acceptance Test Reports
          path: |
            uat_test_report.html
          compression-level: 0
